---
title: 'Analytical Predictive Modeling: Impact of Financial and Economic Indicators on Stock'
author: 'Student: Thao Nguyen Pham <br/> <br/> Instructor: Dr. Emmanuel Thompson'
date: "03/31/2023"
output:
  html_document: default
  pdf_document: default
indent: yes
---
#### **1. PREPARE THE DATASET**

1.1. Import the dataset

* S&P500 dataset 

```{r}
sp500 <- read.csv("C:/Users/PC/Desktop/Project/PredictiveModeling/sp500-1022 (Used).csv")
head(sp500)
```

* JPMorgan Chase dataset 

```{r}
jpm <- read.csv("C:/Users/PC/Desktop/Project/PredictiveModeling/jpm-1022 (Used).csv")
jpm
```

* US 3-month treasury bills dataset 

```{r}
US3M <- read.csv("C:/Users/PC/Desktop/Project/PredictiveModeling/US3M (Used).csv", fileEncoding = 'UTF-8-BOM')
head(US3M)
```

* Economic indicators dataset 

```{r}
indicator <- read.csv("C:/Users/PC/Desktop/Project/PredictiveModeling/Indicators (Used).csv", fileEncoding = 'UTF-8-BOM')
head(indicator)
```

1.2. CALCULATE MARKET QUARTERLY RATE OF RETURN 

```{r}
#create function to calculate quarterly return rate
quarterly_return <- function (df) {
  
  df_quarterly_return <- df #create a copy of the input dataframe
  
  #loop through dataframe to calculate quarterly return, in which current quarter return = ((current price - previous price)/previous price)*100
  for (c in 2:ncol(df_quarterly_return)) {
    for (r in 2:nrow(df_quarterly_return)) {
      df_quarterly_return[r, c+1] <- as.numeric(format((df[r, c] - df[r-1, c])/df[r-1, c]*100), digits = 4)
    }
    df_quarterly_return[1, c+1] = 0 # set the value of the first row = 0 
  }
  return (df_quarterly_return)
}
```

* Calculate market quarterly rate of return
```{r}
sp500_qr <- quarterly_return(sp500)
colnames(sp500_qr) <- c("Date", "sp500_price", "sp500_quarterlyReturn")
head(sp500_qr)
```

* Calculate stock's quarterly rate of return
```{r}
jpm_qr <- quarterly_return(jpm)
colnames(jpm_qr) <- c("Date", "jpm_price", "jpm_quarterlyReturn")
head(jpm_qr)
```

1.3. Merge the quarterly return datasets into 1 table

```{r}
#Merge sp500_wr & jpm_wr & US3M together
ds <- merge(sp500_qr, jpm_qr, by = c("Date" = "Date"), all.x = TRUE)
ds
```

1.4. Find Beta

```{r}
ds$beta <- c(ds$sp500_quarterlyReturn - US3M$Risk.free.Rate)/(ds$jpm_quarterlyReturn - US3M$Risk.free.Rate)
ds
```

#### **II. Development of statistical model**

2.1. Check the normality of the Quarterly Closing Price (QCP)

```{r}
#draw Q-Q plot to check the normality of QCP
qqnorm(jpm$Adj.Close, pch = 1, frame = FALSE)
qqline(jpm$Adj.Close, col = "steelblue", lwd = 2)
```

```{r}
#perform Shapiro-Wilk test for normality
shapiro.test(jpm$Adj.Close) 
#p-value < 0.05 => not normal distributed
```

2.2. AFTER JOHNSON TRANSFORMATION ON MINITAB STATISTICAL SOFTWARE

```{r}
#Import transformed JPM QCP
jpm_trans <- read.csv("C:/Users/PC/Desktop/Project/PredictiveModeling/jpm_trans.csv", fileEncoding = 'UTF-8-BOM')
colnames(jpm_trans)[2] <- "QCP_T"
jpm_trans
```

```{r}
#draw Q-Q plot to check normality of transformed JPM QCP
qqnorm(jpm_trans$QCP_T, pch = 1, frame = FALSE)
qqline(jpm_trans$QCP_T, col = "steelblue", lwd = 2)
```

```{r}
#perform Shapiro-Wilk test for normality after Johnson transformation
shapiro.test(jpm_trans$QCP_T) 
```

2.3. CHECK CORRELATION USING DATA TRANSFORMATION

```{r}
(library(corrplot))
```

```{r}
#Generate the dataset that contains all indicators and transformed JPM QCP
df <- Reduce(function(...) merge(..., all = TRUE, by = "Date"),
       list(ds[, c(1, 6)], indicator, jpm_trans))
df
```

```{r}
#Check the correlation among the indicators
corrplot(cor(df[, c(2:12)]), type = "upper", addCoef.col="orange", number.cex=0.75)
``` 

2.4. VARIANCE INFLATION FACTOR

```{r}
library(car)  
```

```{r}
# Check Variance Inflation Factor (VIF) to verify the existence of multicollinearity among attributable indicators
#fit the regression model
model <- lm(QCP_T ~ beta + PB + PE + FCF.Share + PEG + 
            Dividend.Yield + GDP + Interest.Rate + CPI + PSR,
            data = df)

#view the output of the regression model
summary(model)

#calculate the VIF for each predictor variable in the model
vif(model)
```

DROP HIGH VIF SCORES FACTORS > 10 (Which is GDP & PB)
```{r}
#fit the regression model
model <- lm(QCP_T ~ beta + PE + FCF.Share + PEG + 
            Dividend.Yield + Interest.Rate + CPI + PSR,
            data = df)

#view the output of the regression model
summary(model)

#calculate the VIF for each predictor variable in the model
vif(model)
```

2.5. LASSO REGRESSION

Prepare data for lasso regression
```{r}
library(caTools)
library(caret)
```

```{r}
#create a dataset containing only indicators for training and testing purpose
data <- df[, -1]
y <- as.matrix(data$QCP_T)    #response variable
x <- model.matrix(QCP_T ~ .^2, data)     #predictor variables

# Stratified sampling for balanced class distribution
set.seed(1)  # for reproducibility

y_train_indices <- sample(1:length(y), length(y) * 0.8)  # 80% for training
y_test_indices <- setdiff(1:length(y), y_train_indices)  # 20% remaining for testing
# Create training and testing datasets
y_train <- y[y_train_indices]
y_test <- y[y_test_indices]

x_train_indices <- sample(1:nrow(x), nrow(x) * 0.8)  # 80% for training
x_test_indices <- setdiff(1:nrow(x), x_train_indices)  # 20%remaining for testing
# Create training and testing datasets
x_train <- x[x_train_indices, ]
x_test <- x[x_test_indices, ]

y_test
x_test
```

Find optimal lambda value for lasso regression
```{r}
library(glmnet)
```

```{r}
# Perform k-fold cross-validation to find optimal lambda value (default nfolds = 10)
lasso_reg <- cv.glmnet(x_train, y_train, alpha = 1,standardize = TRUE) 

#find optimal lambda value that minimizes test MSE
best_lambda <- lasso_reg$lambda.min
best_lambda
```

Train LASSO model

```{r}
# Fit the lasso model with the optimal lambda value
lasso_model <- glmnet(x_train, y_train, alpha = 1, lambda = best_lambda, standardize = TRUE)

# Compute R^2 from fact and predicted values
eval_results <- function(fact, predicted, df) {
  SSE <- sum((predicted - fact)^2)
  SST <- sum((fact - mean(fact))^2)
  R_square <- 1 - SSE / SST
  RMSE <- sqrt(SSE/nrow(df)) 
  
  print(paste("SSE:", SSE))
  print(paste("SST:", SST))
  print(paste("R_square:", R_square))
  print(paste("RMSE:", RMSE))
  print("--------------")
  }

#Predict and evaluate lasso model using training dataset
predict_train <- predict(lasso_model, s = best_lambda, newx = x_train)
eval_results(y_train, predict_train, data)

#Predict and evaluate lasso model using testing dataset
predict_test <- predict(lasso_model, s = best_lambda, newx = x_test)
eval_results(y_test, predict_test, data)

#Fit lasso model on full dataset
out <- glmnet(x, y, alpha = 1) # Display coefficients using lambda chosen by CV
lasso_coef <- coef(out, s = best_lambda)
print (lasso_coef)
```

2.6. BACKWARD ELIMINATION
```{r}
```